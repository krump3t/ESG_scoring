# ESG Authenticity Audit â€” Quick-Start Checklist

**Audit**: AV-001-20251026  
**Status**: 203 violations (34 FATAL blocking)  
**Time to Fix**: 14-22 hours  
**Priority**: Start with Phase 1 (FATAL eval/exec)

---

## âš ï¸ CRITICAL: Start Here (Do NOT skip Phase 1)

Phase 1 is **BLOCKING** â€” all other work depends on eliminating eval/exec first.

---

## Day 1: FATAL + Determinism (7-12 hours)

### Morning Session (4-7 hours): Phase 1 - FATAL Violations

**Goal**: Eliminate all 34 eval/exec calls

#### [ ] 1.1 Setup (15 min)
```bash
export SEED=42
export PYTHONHASHSEED=0
git checkout -b audit-remediation-baseline
git tag -a audit-baseline-20251026 -m "Pre-remediation"
python scripts/qa/authenticity_audit.py  # Baseline: 203 violations
```

#### [ ] 1.2 Find eval/exec locations (10 min)
```bash
grep -rn "eval(" --include="*.py" scripts/ > /tmp/eval_locations.txt
grep -rn "exec(" --include="*.py" scripts/ >> /tmp/eval_locations.txt
cat /tmp/eval_locations.txt
```

#### [ ] 1.3 Fix scripts/embed_and_index.py (~1-2 hours)
- [ ] Replace `eval()` with `json.loads()`
- [ ] Use `ast.literal_eval()` for safe literals
- [ ] Add error handling for parse failures
- [ ] Test: `grep -n "eval(" scripts/embed_and_index.py` returns nothing

#### [ ] 1.4 Fix scripts/qa/*.py (~1-2 hours)
- [ ] Replace dynamic imports with `importlib`
- [ ] Replace config eval with `ast.literal_eval()`
- [ ] Test each script still works

#### [ ] 1.5 Verify FATAL fixed (10 min)
```bash
grep -rn "eval\|exec" --include="*.py" apps/ libs/ scripts/
# Expected: 0 results
python scripts/qa/authenticity_audit.py  # Should show 0 FATAL
```

#### [ ] 1.6 Commit Phase 1 (5 min)
```bash
git add scripts/
git commit -m "fix(fatal): eliminate eval/exec (34 violations)"
```

**Break** â˜• (15 min)

---

### Afternoon Session (3-5 hours): Phase 2 - Determinism

**Goal**: Make 3 runs produce identical outputs

#### [ ] 2.1 Fix unseeded random (1 hour)
- [ ] `apps/pipeline/mcp_report_fetcher.py:211`
  - Add: `_rng = random.Random(42)` at top
  - Replace: `random.uniform()` â†’ `_rng.uniform()`
- [ ] `libs/storage/astradb_vector.py:489`
  - Add: `np.random.seed(42)` at top
  - Or use: `_np_rng = np.random.RandomState(42)`
  - Replace: `np.random.randn()` â†’ `_np_rng.randn()`
- [ ] Test: Run twice, verify identical quality scores

#### [ ] 2.2 Fix hash() usage (1 hour)
- [ ] `pipelines/airflow/dags/esg_scoring_dag.py:260`
  - Create: `def deterministic_hash(s): return hashlib.sha256(s.encode()).hexdigest()[:12]`
  - Replace: `hash(name)` â†’ `deterministic_hash(name)`
- [ ] `libs/query/query_synthesizer.py:347`
  - Same pattern: SHA256-based selection
- [ ] Test: Run twice, verify identical IDs

#### [ ] 2.3 Remove timestamps (1-2 hours)
- [ ] `apps/pipeline/demo_flow.py:361`
  - Remove: `"timestamp": time.time()` from parity artifact
- [ ] `apps/evaluation/response_quality.py:132`
  - Replace: `datetime.now()` with content-based hash
  - Use: `hashlib.sha256(json.dumps(params).encode()).hexdigest()[:12]`
- [ ] Test: Artifacts don't change between runs

#### [ ] 2.4 Run determinism test (30 min)
```bash
# Create test script
cat > /tmp/test_det.sh << 'EOF'
#!/bin/bash
export SEED=42 PYTHONHASHSEED=0
for i in 1 2 3; do
    python apps/pipeline/demo_flow.py --company Headlam --year 2024 --output artifacts/run_$i
    sha256sum artifacts/run_$i/* > artifacts/run_${i}_hashes.txt
done
diff artifacts/run_1_hashes.txt artifacts/run_2_hashes.txt
diff artifacts/run_2_hashes.txt artifacts/run_3_hashes.txt
EOF
chmod +x /tmp/test_det.sh
/tmp/test_det.sh
# Expected: No differences
```

#### [ ] 2.5 Commit Phase 2 (5 min)
```bash
git add apps/ libs/ pipelines/
git commit -m "fix(determinism): seed RNGs, use SHA256, remove timestamps (AV01-03)"
```

**End of Day 1** ðŸŽ¯

---

## Day 2: Evidence + Parity + Posture (7-10 hours)

### Morning Session (4-6 hours): Phase 3 - Evidence & Parity

#### [ ] 3.1 Fix manifest provenance (1-2 hours)
- [ ] Find where `artifacts/ingestion/manifest.json` is created
- [ ] Replace `test_hash` with real `hashlib.sha256(content).hexdigest()`
- [ ] Add `content_type` using `python-magic` library
- [ ] Add PDF metadata (title, author, etc.) in `headers` field
- [ ] Test: `grep "test_hash" artifacts/ingestion/manifest.json` returns nothing

#### [ ] 3.2 Add chunk_id to evidence (1 hour)
- [ ] Find evidence extraction code (likely `apps/pipeline/demo_flow.py`)
- [ ] Generate: `chunk_id = f"chunk_{hashlib.sha256(f'{doc_id}|{page}|{span}'.encode()).hexdigest()[:12]}"`
- [ ] Add to evidence dict
- [ ] Test: `cat artifacts/evidence/*.json | jq '.[0].chunk_id'` returns value

#### [ ] 3.3 Fix ID consistency for parity (1-2 hours)
- [ ] Compare: Evidence doc_ids vs topk doc_ids
  ```bash
  cat artifacts/evidence/*.json | jq '.[].doc_id' | sort -u > /tmp/ev_ids.txt
  cat artifacts/pipeline_validation/topk_vs_evidence.json | jq '.topk_doc_ids[]' | sort -u > /tmp/topk_ids.txt
  diff /tmp/ev_ids.txt /tmp/topk_ids.txt
  ```
- [ ] Fix retrieval to use real doc_ids from manifest
- [ ] Or fix evidence to use retrieval doc_ids (choose consistent scheme)
- [ ] Test: Diff should be empty

#### [ ] 3.4 Implement rubric-based scoring (1 hour)
- [ ] Replace heuristic scorer in `apps/pipeline/demo_flow.py:193-353`
- [ ] Use: `from agents.scoring.rubric_scorer import RubricScorer`
- [ ] Load rubric: `scorer = RubricScorer("rubrics/maturity_v3.json")`
- [ ] Enforce: â‰¥2 quotes per theme (already in RubricScorer)
- [ ] Test: `pytest tests/authenticity/test_rubric_compliance_cp.py`

#### [ ] 3.5 Generate maturity.parquet (30 min)
- [ ] Add function to save scores as Parquet
- [ ] Include: org_id, year, theme, stage, confidence, evidence_count
- [ ] Sort deterministically: `df.sort_values(['org_id', 'year', 'theme'])`
- [ ] Test: `ls artifacts/maturity.parquet`

#### [ ] 3.6 Verify parity (30 min)
```bash
cat > /tmp/verify_parity.py << 'EOF'
import json
from pathlib import Path
evidence_ids = set()
for f in Path("artifacts/evidence").glob("*.json"):
    for rec in json.loads(f.read_text()):
        evidence_ids.add(rec["doc_id"])
topk = json.loads(Path("artifacts/pipeline_validation/topk_vs_evidence.json").read_text())
topk_ids = set(topk["topk_doc_ids"])
missing = evidence_ids - topk_ids
print(f"Missing: {len(missing)}")
assert len(missing) == 0, f"Parity fail: {missing}"
EOF
python /tmp/verify_parity.py
```

#### [ ] 3.7 Commit Phase 3 (5 min)
```bash
git add apps/ agents/ artifacts/
git commit -m "fix(evidence): restore provenance and parity gates"
```

**Lunch Break** ðŸ• (45 min)

---

### Afternoon Session (3-4 hours): Phase 4 - Production Posture

#### [ ] 4.1 Implement offline mode (2 hours)
- [ ] Create `libs/embeddings/local.py` with SentenceTransformer
- [ ] Create `libs/storage/memory.py` with in-memory vector store
- [ ] Modify `apps/scoring/pipeline.py` to support `mode="offline"`
- [ ] Test: `SCORING_MODE=offline python apps/pipeline/demo_flow.py`

#### [ ] 4.2 Fix filesystem paths (30 min)
- [ ] `apps/ingestion/parser.py:65`: Change `data/pdf_cache` â†’ `artifacts/cache/pdfs`
- [ ] `apps/evaluation/response_quality.py:745`: Change `reports/` â†’ `artifacts/evaluation/reports/`
- [ ] Update `.dockerignore` to exclude old paths

#### [ ] 4.3 Fix file extensions (30 min)
```bash
# Find JSON masquerading as Parquet
find artifacts/ -name "*.parquet" -exec sh -c '
  if head -1 "$1" | grep -q "^{"; then
    mv "$1" "${1%.parquet}.json"
    echo "Renamed: $1"
  fi
' _ {} \;
```

#### [ ] 4.4 Update Dockerfile (30 min)
- [ ] Add: Pre-download sentence-transformers model
- [ ] Set: `ENV SCORING_MODE=offline`
- [ ] Set: `ENV SEED=42 PYTHONHASHSEED=0`
- [ ] Test: `docker build -t esg-scorer . && docker run --network none esg-scorer`

#### [ ] 4.5 Commit Phase 4 (5 min)
```bash
git add apps/ libs/ Dockerfile
git commit -m "fix(posture): offline mode and filesystem hygiene"
```

**End of Day 2** ðŸŽ¯

---

## Day 3: Silent Errors + Final Verification (3-6 hours)

### Morning Session (2-3 hours): Phase 5 - Silent Failures

#### [ ] 5.1 Add logging to exceptions (2-3 hours)
- [ ] Find all: `except:.*return []` patterns
  ```bash
  grep -rn "except:.*return \[\]" agents/ libs/ apps/
  ```
- [ ] For each location:
  - Add: `import logging; logger = logging.getLogger(__name__)`
  - Add: `logger.error(f"Failed: {e}", exc_info=True)` before `return []`
  - Or return `None` instead of `[]` to signal explicit failure
- [ ] Priority files:
  - `agents/crawler/data_providers/sasb_provider.py` (lines 183, 212, 240, 281, 326)
  - Any other high-traffic paths
- [ ] Test: Run pipeline, check logs for error messages

#### [ ] 5.2 Commit Phase 5 (5 min)
```bash
git add agents/ libs/ apps/
git commit -m "fix(errors): add logging to silent exception handlers (AV08)"
```

**Break** â˜• (15 min)

---

### Final Session (1-3 hours): Phase 6 - Verification

#### [ ] 6.1 Re-run full audit (10 min)
```bash
python scripts/qa/authenticity_audit.py
# Expected: 0 FATAL, <20 WARN (low priority only)
```

#### [ ] 6.2 Three-run determinism test (30 min)
```bash
/tmp/test_det.sh  # From Day 1
# Expected: All 3 runs byte-identical
```

#### [ ] 6.3 Docker test (30 min)
```bash
docker build -t esg-scorer:test .
docker run -d --name test --network none -p 8000:8000 esg-scorer:test
sleep 5
curl http://localhost:8000/health  # Should return 200
curl -X POST http://localhost:8000/score -H "Content-Type: application/json" \
  -d '{"company": "Headlam", "year": 2024}'
# Should return valid JSON without network
docker stop test && docker rm test
```

#### [ ] 6.4 Run full test suite (20-30 min)
```bash
pytest tests/ -v --cov=apps --cov=libs
# Expected: All pass, â‰¥95% coverage
```

#### [ ] 6.5 Type check (10 min)
```bash
mypy --strict apps/api/main.py apps/pipeline/demo_flow.py
# Expected: 0 errors
```

#### [ ] 6.6 Generate completion report (10 min)
```bash
cat > artifacts/audit/remediation_complete.md << 'EOF'
# Remediation Complete

Date: 2025-10-26
Status: âœ… ALL GATES PASSING

## Violations Fixed
- FATAL (eval/exec): 34 â†’ 0
- Determinism: 87 â†’ 0
- Evidence/Parity: 21 â†’ 0
- Silent errors: 74 â†’ logged
- Filesystem: 8 â†’ 0

## Verification
- 3-run determinism: âœ… PASS
- Parity check: âœ… PASS
- Docker offline: âœ… PASS
- Coverage: âœ… 95%+
- Type safety: âœ… mypy strict = 0

Ready for production.
EOF
```

#### [ ] 6.7 Final commit & tag (10 min)
```bash
git add -A
git commit -m "feat: complete authenticity audit remediation

All 203 violations resolved across 6 phases:
- Phase 1: eval/exec elimination (34 FATAL)
- Phase 2: Determinism (87 fixes)
- Phase 3: Evidence & parity (21 fixes)
- Phase 4: Production posture (offline mode)
- Phase 5: Silent errors (74 logged)
- Phase 6: Verification (all gates green)

Protocol: SCA v13.8-MEA
Status: Production-ready"

git tag -a v1.0.0-audit-clean -m "Authenticity audit complete - all gates passing"
git push origin audit-remediation-baseline
git push origin v1.0.0-audit-clean
```

#### [ ] 6.8 Celebrate! ðŸŽ‰

**End of Day 3** ðŸŽ¯

---

## Quick Reference Card

### Must-Have Environment
```bash
export SEED=42
export PYTHONHASHSEED=0
export SCORING_MODE=offline  # For Docker
```

### Quick Checks
```bash
# Audit
python scripts/qa/authenticity_audit.py

# Determinism
/tmp/test_det.sh

# Parity
python /tmp/verify_parity.py

# Docker
docker build -t esg . && docker run --network none esg
```

### Emergency Rollback
```bash
git reset --hard audit-baseline-20251026
# Starts over from clean state
```

---

## Success Criteria

At the end of Day 3, you should have:

- [ ] âœ… 0 FATAL violations
- [ ] âœ… 0 determinism violations  
- [ ] âœ… 3 identical runs (byte-perfect)
- [ ] âœ… Evidence âŠ† topk (parity verified)
- [ ] âœ… Real hashes in manifest (no test_hash)
- [ ] âœ… Rubric-based scoring (â‰¥2 quotes enforced)
- [ ] âœ… maturity.parquet generated
- [ ] âœ… Docker offline mode working
- [ ] âœ… All errors logged (no silent failures)
- [ ] âœ… mypy --strict = 0
- [ ] âœ… Coverage â‰¥95%
- [ ] âœ… Production-ready release tag

---

## Tips

1. **Don't skip Phase 1** â€” FATAL blocks everything else
2. **Test after each sub-phase** â€” catch issues early
3. **Commit frequently** â€” small, logical checkpoints
4. **Use the detailed plan** â€” This checklist is just the overview; see REMEDIATION_PLAN.md for code examples
5. **Ask for help** â€” If stuck >30min on one item, skip and flag for review

---

**Estimated Total Time**: 14-22 hours over 3 days  
**Priority**: Phase 1 (FATAL) must be done first  
**Success Rate**: 95%+ if following plan systematically

Good luck! ðŸš€
